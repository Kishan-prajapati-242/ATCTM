{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMtpsZ9wcSsNDQgRj8kbijj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx0QCjMNKZPy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/ATCTM/EVENT_CLASSIFICATION/EC-demo.csv')\n",
        "df.dropna(subset=['TEXT'], inplace=True)\n",
        "\n",
        "# Encode categorical columns\n",
        "le_event = LabelEncoder()\n",
        "le_emotion = LabelEncoder()\n",
        "le_tense = LabelEncoder()\n",
        "\n",
        "# Encoding target labels\n",
        "df['EVENT_TYPE_ID'] = le_event.fit_transform(df['EVENT_TYPE'])\n",
        "df['EMOTION_ID'] = le_emotion.fit_transform(df['EMOTION'])\n",
        "df['TENSE_ID'] = le_tense.fit_transform(df['TENSE'])\n",
        "df['SARCASM_ID'] = df['SARCASM'].astype(int)\n",
        "\n",
        "# Dataset Class\n",
        "class EventDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len=128):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        encoded = tokenizer(row['TEXT'], padding='max_length', truncation=True, max_length=self.max_len, return_tensors='pt')\n",
        "        return {\n",
        "            'input_ids': encoded['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoded['attention_mask'].squeeze(0),\n",
        "            'event_type': torch.tensor(row['EVENT_TYPE_ID']),\n",
        "            'emotion': torch.tensor(row['EMOTION_ID']),\n",
        "            'sarcasm': torch.tensor(row['SARCASM_ID']),\n",
        "            'tense': torch.tensor(row['TENSE_ID']),\n",
        "        }\n",
        "\n",
        "# Model Definition\n",
        "class EventClassifier(nn.Module):\n",
        "    def __init__(self, num_event_types, num_emotions, num_tenses):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.shared = nn.Linear(768, 512)\n",
        "\n",
        "        self.event_head = nn.Linear(512, num_event_types)\n",
        "        self.emotion_head = nn.Linear(512, num_emotions)\n",
        "        self.sarcasm_head = nn.Linear(512, 1)\n",
        "        self.tense_head = nn.Linear(512, num_tenses)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        x = self.dropout(output.pooler_output)\n",
        "        x = self.shared(x)\n",
        "\n",
        "        return {\n",
        "            'event_type': self.event_head(x),\n",
        "            'emotion': self.emotion_head(x),\n",
        "            'sarcasm': torch.sigmoid(self.sarcasm_head(x)),\n",
        "            'tense': self.tense_head(x)\n",
        "        }\n",
        "\n",
        "# Tokenizer and Dataset\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
        "train_data = EventDataset(train_df, tokenizer)\n",
        "val_data = EventDataset(val_df, tokenizer)\n",
        "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=8)\n",
        "\n",
        "# Training Setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = EventClassifier(len(le_event.classes_), len(le_emotion.classes_), len(le_tense.classes_)).to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn_ce = nn.CrossEntropyLoss()\n",
        "loss_fn_bce = nn.BCELoss()\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(4):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(train_loader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "\n",
        "        loss_event = loss_fn_ce(outputs['event_type'], batch['event_type'].to(device))\n",
        "        loss_emo = loss_fn_ce(outputs['emotion'], batch['emotion'].to(device))\n",
        "        loss_sar = loss_fn_bce(outputs['sarcasm'].squeeze(), batch['sarcasm'].float().to(device))\n",
        "        loss_tense = loss_fn_ce(outputs['tense'], batch['tense'].to(device))\n",
        "\n",
        "        loss = loss_event + loss_emo + loss_sar + loss_tense\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")\n",
        "\n",
        "# Utility Functions\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    return round((blob.sentiment.polarity + 1) / 2, 3)\n",
        "\n",
        "def analyze_certainty(text):\n",
        "    certainty_words = [\"sure\", \"definitely\", \"certain\", \"guarantee\"]\n",
        "    return 1.0 if any(word in text.lower() for word in certainty_words) else 0.6\n",
        "\n",
        "# Inference\n",
        "model.eval()\n",
        "def predict_event(text):\n",
        "    encoded = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=128)\n",
        "    input_ids = encoded['input_ids'].to(device)\n",
        "    attention_mask = encoded['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "\n",
        "    pred_event = le_event.inverse_transform([torch.argmax(outputs['event_type'], dim=1).item()])[0]\n",
        "    pred_emotion = le_emotion.inverse_transform([torch.argmax(outputs['emotion'], dim=1).item()])[0]\n",
        "    pred_sarcasm = outputs['sarcasm'].item() > 0.5\n",
        "    pred_tense = le_tense.inverse_transform([torch.argmax(outputs['tense'], dim=1).item()])[0]\n",
        "\n",
        "    return {\n",
        "        \"TEXT\": text,\n",
        "        \"EVENT_TYPE\": pred_event,\n",
        "        \"EVENT_GROUP\": \"employment\",\n",
        "        \"SENTIMENT_VALENCE\": analyze_sentiment(text),\n",
        "        \"EMOTION\": pred_emotion,\n",
        "        \"SARCASM\": pred_sarcasm,\n",
        "        \"TENSE\": pred_tense,\n",
        "        \"CERTAINTY\": analyze_certainty(text)\n",
        "    }\n",
        "\n",
        "# Example Usage\n",
        "print(predict_event(\"They finally laid me off after months of warnings.\"))\n",
        "print(predict_event(\"Just got hired at a startup in Berlin. I'm thrilled!\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts = [\n",
        "    \"I just lost my job today and I feel completely defeated.\",\n",
        "    \"They hired me for the dream role I always wanted!\",\n",
        "    \"Laid off again, and it stings just like the first time.\",\n",
        "    \"Finally got the offer letter! Starting next Monday!\",\n",
        "    \"They fired me over a small mistake, feels unfair.\",\n",
        "    \"Can't believe I actually made it through the interview process!\",\n",
        "    \"Got laid off along with half the team, it's chaos.\",\n",
        "    \"I'm joining a new firm next week, pumped for the switch.\",\n",
        "    \"My boss just fired me over a petty argument.\",\n",
        "    \"Excited to start fresh with this new opportunity.\",\n",
        "    \"They gave me a pink slip without warning.\",\n",
        "    \"So thrilled to be hired by a company I admire!\",\n",
        "    \"I was let go due to cost-cutting, nothing personal they said.\",\n",
        "    \"I nailed the interview and just received the job confirmation.\",\n",
        "    \"After years of service, they just fired me like that.\",\n",
        "    \"Job hunt finally ends — I’m hired!\",\n",
        "    \"Fired again. I think I’m the problem.\",\n",
        "    \"Secured a position at a firm I’ve always respected.\",\n",
        "    \"They dismissed me right before the holidays. Brutal.\",\n",
        "    \"Starting my new role next Monday — excited and nervous!\"\n",
        "]\n",
        "\n",
        "for txt in sample_texts:\n",
        "    print(predict_event(txt))"
      ],
      "metadata": {
        "id": "N-fLoznmRZRO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
