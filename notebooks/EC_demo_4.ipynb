{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPnIQr1MdwJWv4e+ui+oips",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kishan-prajapati-242/ATCTM/blob/main/notebooks/EC_demo_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "from textblob import TextBlob\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "id": "e37GglWwNCCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/ATCTM/EVENT_CLASSIFICATION/EC-demo.csv')\n",
        "df.dropna(subset=['TEXT'], inplace=True)\n",
        "\n",
        "# Shuffle dataset\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Encode categorical columns\n",
        "le_event = LabelEncoder()\n",
        "le_emotion = LabelEncoder()\n",
        "le_tense = LabelEncoder()\n",
        "\n",
        "# Encoding target labels\n",
        "df['EVENT_TYPE_ID'] = le_event.fit_transform(df['EVENT_TYPE'])\n",
        "df['EMOTION_ID'] = le_emotion.fit_transform(df['EMOTION'])\n",
        "df['TENSE_ID'] = le_tense.fit_transform(df['TENSE'])\n",
        "df['SARCASM_ID'] = df['SARCASM'].astype(int)\n",
        "\n",
        "# Split into 800 training and 200 testing manually\n",
        "train_df = df.iloc[:800]\n",
        "val_df = df.iloc[800:]\n",
        "\n",
        "# Dataset Class\n",
        "class EventDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len=128):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        encoded = self.tokenizer(row['TEXT'], padding='max_length', truncation=True, max_length=self.max_len, return_tensors='pt')\n",
        "        return {\n",
        "            'input_ids': encoded['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoded['attention_mask'].squeeze(0),\n",
        "            'event_type': torch.tensor(row['EVENT_TYPE_ID']),\n",
        "            'emotion': torch.tensor(row['EMOTION_ID']),\n",
        "            'sarcasm': torch.tensor(row['SARCASM_ID']),\n",
        "            'tense': torch.tensor(row['TENSE_ID']),\n",
        "        }\n",
        "\n",
        "# Improved Model Definition with task-specific projections\n",
        "class EventClassifier(nn.Module):\n",
        "    def __init__(self, num_event_types, num_emotions, num_tenses):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.shared = nn.Linear(768, 512)\n",
        "\n",
        "        self.event_proj = nn.Linear(512, 256)\n",
        "        self.emotion_proj = nn.Linear(512, 256)\n",
        "        self.sarcasm_proj = nn.Linear(512, 256)\n",
        "        self.tense_proj = nn.Linear(512, 256)\n",
        "\n",
        "        self.event_head = nn.Linear(256, num_event_types)\n",
        "        self.emotion_head = nn.Linear(256, num_emotions)\n",
        "        self.sarcasm_head = nn.Linear(256, 1)\n",
        "        self.tense_head = nn.Linear(256, num_tenses)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        x = self.dropout(output.pooler_output)\n",
        "        x = self.shared(x)\n",
        "\n",
        "        return {\n",
        "            'event_type': self.event_head(self.event_proj(x)),\n",
        "            'emotion': self.emotion_head(self.emotion_proj(x)),\n",
        "            'sarcasm': torch.sigmoid(self.sarcasm_head(self.sarcasm_proj(x))),\n",
        "            'tense': self.tense_head(self.tense_proj(x))\n",
        "        }\n",
        "\n",
        "# Tokenizer and Dataset\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "train_data = EventDataset(train_df, tokenizer)\n",
        "val_data = EventDataset(val_df, tokenizer)\n",
        "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=8)\n",
        "\n",
        "# Class weights for emotion\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "weights = compute_class_weight('balanced', classes=np.unique(df['EMOTION_ID']), y=df['EMOTION_ID'])\n",
        "emotion_weights = torch.tensor(weights, dtype=torch.float)\n",
        "\n",
        "# Training Setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = EventClassifier(len(le_event.classes_), len(le_emotion.classes_), len(le_tense.classes_)).to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn_ce = nn.CrossEntropyLoss()\n",
        "loss_fn_emo = nn.CrossEntropyLoss(weight=emotion_weights.to(device))\n",
        "loss_fn_bce = nn.BCELoss()\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(4):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(train_loader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "\n",
        "        loss_event = loss_fn_ce(outputs['event_type'], batch['event_type'].to(device))\n",
        "        loss_emo = loss_fn_emo(outputs['emotion'], batch['emotion'].to(device))\n",
        "        loss_sar = loss_fn_bce(outputs['sarcasm'].squeeze(), batch['sarcasm'].float().to(device))\n",
        "        loss_tense = loss_fn_ce(outputs['tense'], batch['tense'].to(device))\n",
        "\n",
        "        loss = loss_event + loss_emo + loss_sar + loss_tense\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "7jPrsvnkU0N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Evaluation Metrics\n",
        "model.eval()\n",
        "all_preds = {'event_type': [], 'emotion': [], 'sarcasm': [], 'tense': []}\n",
        "all_labels = {'event_type': [], 'emotion': [], 'sarcasm': [], 'tense': []}\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "\n",
        "        all_preds['event_type'] += outputs['event_type'].argmax(dim=1).cpu().tolist()\n",
        "        all_labels['event_type'] += batch['event_type'].tolist()\n",
        "\n",
        "        all_preds['emotion'] += outputs['emotion'].argmax(dim=1).cpu().tolist()\n",
        "        all_labels['emotion'] += batch['emotion'].tolist()\n",
        "\n",
        "        all_preds['tense'] += outputs['tense'].argmax(dim=1).cpu().tolist()\n",
        "        all_labels['tense'] += batch['tense'].tolist()\n",
        "\n",
        "        all_preds['sarcasm'] += (outputs['sarcasm'] > 0.5).int().cpu().squeeze().tolist()\n",
        "        all_labels['sarcasm'] += batch['sarcasm'].tolist()\n",
        "\n",
        "# === EVENT TYPE REPORT ===\n",
        "print(\"\\nEvent Type Classification Report:\")\n",
        "print(classification_report(\n",
        "    all_labels['event_type'],\n",
        "    all_preds['event_type'],\n",
        "    target_names=le_event.classes_\n",
        "))\n",
        "\n",
        "event_acc = accuracy_score(all_labels['event_type'], all_preds['event_type'])\n",
        "print(f\"\\nEvent Type Accuracy: {event_acc * 100:.2f}% out of 100\\n\")"
      ],
      "metadata": {
        "id": "6Em9ffh0X-Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJE0GtTSM6rP"
      },
      "outputs": [],
      "source": [
        "sample_texts = [\n",
        "    # got_hired\n",
        "    \"Just signed the offer letter! I'm finally hired at a real tech company!\",\n",
        "    \"Out of nowhere, they called back and said I got the job. Unreal!\",\n",
        "\n",
        "    # got_fired\n",
        "    \"Got fired this morning. Still trying to process what just happened.\",\n",
        "    \"My manager let me go after a 5-minute meeting. No warnings, nothing.\",\n",
        "\n",
        "    # got_laid_off\n",
        "    \"Our entire department was laid off due to budget cuts.\",\n",
        "    \"I was laid off today. Honestly, I saw it coming but it still hurts.\",\n",
        "\n",
        "    # got_promoted\n",
        "    \"After months of hard work, I finally got promoted to team lead!\",\n",
        "    \"Surprise email today — I’ve been promoted to senior analyst!\",\n",
        "\n",
        "    # got_demoted\n",
        "    \"Apparently I’m not 'strategic enough'. Just got demoted.\",\n",
        "    \"Back to junior level... they really demoted me without proper explanation.\",\n",
        "\n",
        "    # changed_jobs\n",
        "    \"I just switched jobs! New city, new team, new energy!\",\n",
        "    \"Left my old company last week — started at a startup today!\",\n",
        "\n",
        "    # started_new_career\n",
        "    \"I quit teaching and officially started my new career in UX design!\",\n",
        "    \"Day 1 as a data analyst after leaving hospitality — a fresh chapter begins!\",\n",
        "\n",
        "    # retired\n",
        "    \"Last day at work today — after 40 years, I'm finally retired!\",\n",
        "    \"Retired as of this morning. Bittersweet but grateful for the journey.\",\n",
        "\n",
        "    # got_raise\n",
        "    \"Just got a raise! My efforts are finally being recognized!\",\n",
        "    \"They bumped my salary up by 10%! Didn’t expect that at all!\",\n",
        "\n",
        "    # got_pay_cut\n",
        "    \"Company reduced my pay again... this is getting ridiculous.\",\n",
        "    \"Was told my salary is being slashed due to company restructuring.\"\n",
        "]\n",
        "\n",
        "for txt in sample_texts:\n",
        "    print(predict_event(txt))"
      ]
    }
  ]
}