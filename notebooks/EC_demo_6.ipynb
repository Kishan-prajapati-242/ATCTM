{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOFWr4yJUx+WghtbzV2n3bW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVh4rUgHhts5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "from textblob import TextBlob\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ATCTM/EVENT_CLASSIFICATION/EC-demo.csv')\n",
        "df.dropna(subset=['TEXT'], inplace=True)\n",
        "\n",
        "# Generalize Event Types\n",
        "def generalize_event_type(label):\n",
        "    if label in ['got_hired', 'started_new_career']:\n",
        "        return 'job_entry'\n",
        "    elif label in ['got_fired', 'got_laid_off', 'retired', 'failed_interview']:\n",
        "        return 'job_exit'\n",
        "    elif label in ['changed_jobs', 'became_freelancer', 'started_business']:\n",
        "        return 'job_transition'\n",
        "    elif label in ['got_demoted', 'got_pay_cut', 'business_failed']:\n",
        "        return 'job_loss'\n",
        "    elif label in ['got_promoted', 'got_raise', 'got_tenure', 'got_work_award']:\n",
        "        return 'job_gain'\n",
        "    elif label in ['got_sabbatical', 'got_late_to_work', 'missed_deadline']:\n",
        "        return 'job_break'\n",
        "    elif label in ['workplace_harassment']:\n",
        "        return 'workplace_issue'\n",
        "    return 'other'\n",
        "\n",
        "df['EVENT_GENERAL'] = df['EVENT_TYPE'].apply(generalize_event_type)\n",
        "\n",
        "# Encode categorical columns\n",
        "le_event = LabelEncoder()\n",
        "le_general = LabelEncoder()\n",
        "df['EVENT_TYPE_ID'] = le_event.fit_transform(df['EVENT_TYPE'])\n",
        "df['EVENT_GENERAL_ID'] = le_general.fit_transform(df['EVENT_GENERAL'])\n",
        "\n",
        "# Stratified Split\n",
        "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_idx, val_idx in splitter.split(df, df['EVENT_TYPE_ID']):\n",
        "    train_df = df.iloc[train_idx].reset_index(drop=True)\n",
        "    val_df = df.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "# Dataset Class\n",
        "class EventDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len=128):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        encoded = self.tokenizer(row['TEXT'], padding='max_length', truncation=True, max_length=self.max_len, return_tensors='pt')\n",
        "        return {\n",
        "            'input_ids': encoded['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoded['attention_mask'].squeeze(0),\n",
        "            'event_type': torch.tensor(row['EVENT_GENERAL_ID']),\n",
        "        }\n",
        "\n",
        "# Model Definition\n",
        "class EventClassifier(nn.Module):\n",
        "    def __init__(self, num_event_types):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.shared = nn.Linear(768, 512)\n",
        "        self.event_proj = nn.Linear(512, 256)\n",
        "        self.event_head = nn.Linear(256, num_event_types)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        x = self.dropout(output.pooler_output)\n",
        "        x = self.shared(x)\n",
        "        return self.event_head(self.event_proj(x))\n",
        "\n",
        "# Tokenizer and DataLoader\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "train_data = EventDataset(train_df, tokenizer)\n",
        "val_data = EventDataset(val_df, tokenizer)\n",
        "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=8)\n",
        "\n",
        "# Setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = EventClassifier(len(le_general.classes_)).to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn_ce = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(4):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(train_loader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['event_type'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = loss_fn_ce(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")"
      ],
      "metadata": {
        "id": "RWnLorikiBR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['event_type'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        all_preds += outputs.argmax(dim=1).cpu().tolist()\n",
        "        all_labels += labels.cpu().tolist()\n",
        "\n",
        "print(\"\\nGeneralized Event Type Classification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=le_general.classes_))\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"\\nGeneralized Event Type Accuracy: {accuracy * 100:.2f}% out of 100\\n\")\n",
        "\n",
        "# Utility Functions\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    score = sid.polarity_scores(text)['compound']\n",
        "    normalized = round((score + 1) / 2, 1)\n",
        "    return max(min(normalized, 1.0), 0.0)\n",
        "\n",
        "def analyze_certainty(text):\n",
        "    certainty_keywords = [\"sure\", \"definitely\", \"certain\", \"guarantee\", \"confident\", \"no doubt\"]\n",
        "    fuzzy_keywords = [\"maybe\", \"possibly\", \"might\", \"not sure\", \"doubt\"]\n",
        "    text = text.lower()\n",
        "    if any(w in text for w in certainty_keywords):\n",
        "        return 1.0\n",
        "    elif any(w in text for w in fuzzy_keywords):\n",
        "        return 0.3\n",
        "    return 0.6\n",
        "\n",
        "# Inference\n",
        "def predict_event(text):\n",
        "    model.eval()\n",
        "    encoded = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=128)\n",
        "    input_ids = encoded['input_ids'].to(device)\n",
        "    attention_mask = encoded['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "\n",
        "    pred_general = le_general.inverse_transform([torch.argmax(outputs, dim=1).item()])[0]\n",
        "\n",
        "    return {\n",
        "        \"TEXT\": text,\n",
        "        \"EVENT_GENERAL\": pred_general,\n",
        "        \"EVENT_GROUP\": \"employment\",\n",
        "        \"SENTIMENT_VALENCE\": analyze_sentiment(text),\n",
        "        \"CERTAINTY\": analyze_certainty(text)\n",
        "    }\n",
        "\n",
        "# Example Usage\n",
        "print(predict_event(\"They finally laid me off after months of warnings.\"))\n",
        "print(predict_event(\"Just got hired at a startup in Berlin. I'm thrilled!\"))\n"
      ],
      "metadata": {
        "id": "Ty58szS1iDiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts = [\n",
        "    # got_hired\n",
        "    \"Landed a job at Amazon! Starting next month — dream come true.\",\n",
        "    \"Finally got hired after 6 months of applying everywhere!\",\n",
        "\n",
        "    # got_fired\n",
        "    \"I got fired for missing a single deadline. Brutal.\",\n",
        "    \"Fired today. No severance, no explanation. Just like that.\",\n",
        "\n",
        "    # got_laid_off\n",
        "    \"Mass layoffs hit us today. I'm officially unemployed.\",\n",
        "    \"Got laid off from my role — feels surreal and scary.\",\n",
        "\n",
        "    # got_promoted\n",
        "    \"Promotion confirmed! I'm the new marketing lead!\",\n",
        "    \"Manager just announced my promotion during the meeting. Still shocked!\",\n",
        "\n",
        "    # got_demoted\n",
        "    \"Was demoted today. They said it's 'temporary'. Yeah, right.\",\n",
        "    \"Got moved back to associate level. Basically a demotion.\",\n",
        "\n",
        "    # changed_jobs\n",
        "    \"Switched from banking to edtech — already loving the new culture.\",\n",
        "    \"Changed jobs last week. It’s a bit chaotic but exciting!\",\n",
        "\n",
        "    # started_new_career\n",
        "    \"Started a new chapter as a freelance writer!\",\n",
        "    \"Quit my job to pursue graphic design — feels right finally.\",\n",
        "\n",
        "    # retired\n",
        "    \"Clocked out for the last time — officially retired!\",\n",
        "    \"I’m retired now. Looking forward to gardening and naps.\",\n",
        "\n",
        "    # got_raise\n",
        "    \"My boss surprised me with a raise today — totally unexpected!\",\n",
        "    \"Annual review went great — got a decent raise!\",\n",
        "\n",
        "    # got_pay_cut\n",
        "    \"Pay cut hits again. Not sure how I’ll manage rent this month.\",\n",
        "    \"They reduced my salary by 15% due to performance. Pretty demotivating.\",\n",
        "\n",
        "    # started_business\n",
        "    \"Launched my online store today — finally a business owner!\",\n",
        "    \"Started my own consulting firm — day one is here!\",\n",
        "\n",
        "    # business_failed\n",
        "    \"My business couldn’t survive the recession. Shutting down now.\",\n",
        "    \"We had to close shop. Startup failed after two years of grind.\",\n",
        "\n",
        "    # got_late_to_work\n",
        "    \"Was late to work again. Boss wasn’t thrilled.\",\n",
        "    \"Woke up late and missed the morning meeting. Oops!\",\n",
        "\n",
        "    # missed_deadline\n",
        "    \"Missed the project deadline. Client isn’t happy.\",\n",
        "    \"Another deadline missed... really need to manage my time better.\",\n",
        "\n",
        "    # got_work_award\n",
        "    \"Won best performer of the year! Feeling proud!\",\n",
        "    \"Received the excellence award at work — huge moment for me!\",\n",
        "\n",
        "    # workplace_harassment\n",
        "    \"Facing harassment at work but HR isn’t taking action.\",\n",
        "    \"My coworker keeps making inappropriate comments. I’ve reported it.\",\n",
        "\n",
        "    # got_sabbatical\n",
        "    \"Approved for a 3-month sabbatical — can’t wait to travel.\",\n",
        "    \"Finally taking a sabbatical after 8 years of non-stop work.\",\n",
        "\n",
        "    # became_freelancer\n",
        "    \"Left my 9-to-5 to become a full-time freelancer!\",\n",
        "    \"Now freelancing for startups worldwide — loving the freedom!\",\n",
        "\n",
        "    # got_tenure\n",
        "    \"Received tenure today! Officially permanent faculty.\",\n",
        "    \"Tenure granted. All the late nights finally paid off.\",\n",
        "\n",
        "    # failed_interview\n",
        "    \"Didn't make it past the second round. Another failed interview.\",\n",
        "    \"Failed yet another interview. Starting to lose hope.\"\n",
        "]\n",
        "\n",
        "for txt in sample_texts:\n",
        "    print(predict_event(txt))"
      ],
      "metadata": {
        "id": "K5OjbRUXkXBl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}