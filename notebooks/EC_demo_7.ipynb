{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNozi9iue4kDC+l19D09o52",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kishan-prajapati-242/ATCTM/blob/main/notebooks/EC_demo_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jpXKQSJoxss"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import pickle\n",
        "import joblib\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"✓ All libraries imported successfully!\")\n",
        "print(f\"✓ PyTorch version: {torch.__version__}\")\n",
        "print(f\"✓ Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    # Model\n",
        "    model_name = 'microsoft/deberta-v3-base'\n",
        "    max_length = 256\n",
        "\n",
        "    # Training\n",
        "    batch_size = 16\n",
        "    learning_rate = 2e-5\n",
        "    num_epochs = 20\n",
        "    warmup_steps = 500\n",
        "    weight_decay = 0.01\n",
        "\n",
        "    # Architecture\n",
        "    use_auxiliary_features = True\n",
        "    auxiliary_feature_dim = 128\n",
        "    hidden_dim = 768\n",
        "    num_attention_heads = 12\n",
        "    num_transformer_layers = 2\n",
        "    dropout_rate = 0.3\n",
        "    label_smoothing = 0.1\n",
        "\n",
        "    # Training strategy\n",
        "    gradient_accumulation_steps = 2\n",
        "    max_grad_norm = 1.0\n",
        "    early_stopping_patience = 5\n",
        "\n",
        "    # Device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "config = Config()\n",
        "print(f\"Configuration loaded. Device: {config.device}\")"
      ],
      "metadata": {
        "id": "noAoQk0fpSKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/ATCTM/EVENT_CLASSIFICATION/EC-demo.csv')\n"
      ],
      "metadata": {
        "id": "GpYkW5xOpcyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check missing values\n",
        "print(\"Missing values:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Check data types\n",
        "print(\"Data types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Event type distribution\n",
        "print(\"Event type distribution:\")\n",
        "event_counts = df['EVENT_TYPE'].value_counts()\n",
        "print(event_counts)\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(12, 6))\n",
        "event_counts.plot(kind='bar')\n",
        "plt.title('Distribution of Event Types')\n",
        "plt.xlabel('Event Type')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Check unique values\n",
        "print(\"\\nUnique values in auxiliary columns:\")\n",
        "for col in ['SENTIMENT_VALENCE', 'EMOTION', 'SARCASM', 'TENSE', 'CERTAINTY', 'GENERATED']:\n",
        "    if col in ['SENTIMENT_VALENCE', 'CERTAINTY']:\n",
        "        print(f\"{col}: {df[col].dtype} (range: {df[col].min():.2f} - {df[col].max():.2f})\")\n",
        "    else:\n",
        "        unique_vals = df[col].dropna().unique()\n",
        "        print(f\"{col}: {len(unique_vals)} unique values - {list(unique_vals)[:10]}\")\n"
      ],
      "metadata": {
        "id": "HA1WPxsopsl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AuxiliaryFeatureExtractor:\n",
        "    def __init__(self):\n",
        "        self.emotion_encoder = LabelEncoder()\n",
        "        self.tense_encoder = LabelEncoder()\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def fit(self, df):\n",
        "        # Handle missing values\n",
        "        df_copy = df.copy()\n",
        "        df_copy['EMOTION'] = df_copy['EMOTION'].fillna('neutral')\n",
        "        df_copy['TENSE'] = df_copy['TENSE'].fillna('present')\n",
        "\n",
        "        # Fit encoders\n",
        "        self.emotion_encoder.fit(df_copy['EMOTION'])\n",
        "        self.tense_encoder.fit(df_copy['TENSE'])\n",
        "\n",
        "        # Fit scaler\n",
        "        features = self._encode(df)\n",
        "        self.scaler.fit(features)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _encode(self, df):\n",
        "        features = []\n",
        "        df_copy = df.copy()\n",
        "\n",
        "        # SENTIMENT_VALENCE: numeric (0.0 to 1.0)\n",
        "        features.append(df_copy['SENTIMENT_VALENCE'].fillna(0.5).values)\n",
        "\n",
        "        # EMOTION: categorical\n",
        "        df_copy['EMOTION'] = df_copy['EMOTION'].fillna('neutral')\n",
        "        features.append(self.emotion_encoder.transform(df_copy['EMOTION']))\n",
        "\n",
        "        # SARCASM: TRUE/FALSE to 1/0\n",
        "        sarcasm_map = {'TRUE': 1, 'True': 1, True: 1, 'FALSE': 0, 'False': 0, False: 0}\n",
        "        features.append(df_copy['SARCASM'].map(sarcasm_map).fillna(0).astype(int).values)\n",
        "\n",
        "        # TENSE: categorical\n",
        "        df_copy['TENSE'] = df_copy['TENSE'].fillna('present')\n",
        "        features.append(self.tense_encoder.transform(df_copy['TENSE']))\n",
        "\n",
        "        # CERTAINTY: numeric (0.0 to 1.0)\n",
        "        features.append(df_copy['CERTAINTY'].fillna(0.5).values)\n",
        "\n",
        "        # GENERATED: TRUE/FALSE to 1/0\n",
        "        generated_map = {'TRUE': 1, 'True': 1, True: 1, 'FALSE': 0, 'False': 0, False: 0}\n",
        "        features.append(df_copy['GENERATED'].map(generated_map).fillna(0).astype(int).values)\n",
        "\n",
        "        return np.column_stack(features)\n",
        "\n",
        "    def transform(self, df):\n",
        "        features = self._encode(df)\n",
        "        return self.scaler.transform(features)\n",
        "\n",
        "print(\"✓ Auxiliary feature extractor defined\")\n"
      ],
      "metadata": {
        "id": "uBa_KcqCqJ_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EventDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, auxiliary_features=None, max_length=256):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.auxiliary_features = auxiliary_features\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        item = {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "        if self.auxiliary_features is not None:\n",
        "            item['auxiliary_features'] = torch.tensor(\n",
        "                self.auxiliary_features[idx],\n",
        "                dtype=torch.float\n",
        "            )\n",
        "\n",
        "        return item\n",
        "\n",
        "print(\"✓ Dataset class defined\")\n"
      ],
      "metadata": {
        "id": "zDeJqyKuqOKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiModalEventClassifier(nn.Module):\n",
        "    def __init__(self, config, num_labels, auxiliary_feature_size=0):\n",
        "        super().__init__()\n",
        "\n",
        "        # Load pre-trained transformer\n",
        "        self.transformer = AutoModel.from_pretrained(config.model_name)\n",
        "\n",
        "        # Freeze embeddings\n",
        "        for param in self.transformer.embeddings.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Auxiliary feature processing\n",
        "        self.use_auxiliary = config.use_auxiliary_features and auxiliary_feature_size > 0\n",
        "        if self.use_auxiliary:\n",
        "            self.auxiliary_encoder = nn.Sequential(\n",
        "                nn.Linear(auxiliary_feature_size, config.auxiliary_feature_dim),\n",
        "                nn.LayerNorm(config.auxiliary_feature_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(config.dropout_rate),\n",
        "                nn.Linear(config.auxiliary_feature_dim, config.auxiliary_feature_dim),\n",
        "                nn.LayerNorm(config.auxiliary_feature_dim),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "        # Attention for text features\n",
        "        self.text_attention = nn.MultiheadAttention(\n",
        "            embed_dim=self.transformer.config.hidden_size,\n",
        "            num_heads=config.num_attention_heads,\n",
        "            dropout=config.dropout_rate,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Feature fusion\n",
        "        fusion_input_dim = self.transformer.config.hidden_size\n",
        "        if self.use_auxiliary:\n",
        "            fusion_input_dim += config.auxiliary_feature_dim\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(fusion_input_dim, config.hidden_dim),\n",
        "            nn.LayerNorm(config.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(config.dropout_rate),\n",
        "            nn.Linear(config.hidden_dim, config.hidden_dim),\n",
        "            nn.LayerNorm(config.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(config.dropout_rate),\n",
        "            nn.Linear(config.hidden_dim, num_labels)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, auxiliary_features=None):\n",
        "        # Get transformer outputs\n",
        "        outputs = self.transformer(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        # Apply attention\n",
        "        hidden_state = outputs.last_hidden_state\n",
        "        attended, _ = self.text_attention(\n",
        "            hidden_state, hidden_state, hidden_state,\n",
        "            key_padding_mask=~attention_mask.bool()\n",
        "        )\n",
        "\n",
        "        # Pool\n",
        "        text_features = (attended * attention_mask.unsqueeze(-1)).sum(dim=1) / attention_mask.sum(dim=1, keepdim=True)\n",
        "\n",
        "        # Combine with auxiliary features\n",
        "        if self.use_auxiliary and auxiliary_features is not None:\n",
        "            aux_features = self.auxiliary_encoder(auxiliary_features)\n",
        "            combined_features = torch.cat([text_features, aux_features], dim=-1)\n",
        "        else:\n",
        "            combined_features = text_features\n",
        "\n",
        "        # Classify\n",
        "        logits = self.classifier(combined_features)\n",
        "\n",
        "        return logits\n",
        "\n",
        "print(\"✓ Model architecture defined\")\n"
      ],
      "metadata": {
        "id": "4YirG1D4qRZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, dataloader, optimizer, scheduler, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    for batch in tqdm(dataloader, desc='Training'):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        auxiliary_features = None\n",
        "        if 'auxiliary_features' in batch:\n",
        "            auxiliary_features = batch['auxiliary_features'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            auxiliary_features=auxiliary_features\n",
        "        )\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    return total_loss / len(dataloader), accuracy\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc='Evaluating'):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            auxiliary_features = None\n",
        "            if 'auxiliary_features' in batch:\n",
        "                auxiliary_features = batch['auxiliary_features'].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                auxiliary_features=auxiliary_features\n",
        "            )\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    return total_loss / len(dataloader), accuracy, predictions, true_labels\n",
        "\n",
        "print(\"✓ Training functions defined\")\n"
      ],
      "metadata": {
        "id": "bVaYH6sSqVFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df['event_type_encoded'] = label_encoder.fit_transform(df['EVENT_TYPE'])\n",
        "\n",
        "print(f\"Number of event types: {len(label_encoder.classes_)}\")\n",
        "print(f\"Event types: {list(label_encoder.classes_)}\")\n",
        "\n",
        "# Extract auxiliary features\n",
        "aux_extractor = AuxiliaryFeatureExtractor()\n",
        "aux_extractor.fit(df)\n",
        "auxiliary_features = aux_extractor.transform(df)\n",
        "print(f\"Auxiliary features shape: {auxiliary_features.shape}\")\n",
        "\n",
        "# Split data\n",
        "X_train, X_val, y_train, y_val, aux_train, aux_val = train_test_split(\n",
        "    df['TEXT'].values,\n",
        "    df['event_type_encoded'].values,\n",
        "    auxiliary_features,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['event_type_encoded']\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Validation samples: {len(X_val)}\")\n"
      ],
      "metadata": {
        "id": "rYLrWa-yqZA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = EventDataset(X_train, y_train, tokenizer, aux_train, config.max_length)\n",
        "val_dataset = EventDataset(X_val, y_val, tokenizer, aux_val, config.max_length)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"✓ DataLoaders created\")\n",
        "print(f\"  - Train batches: {len(train_loader)}\")\n",
        "print(f\"  - Val batches: {len(val_loader)}\")\n"
      ],
      "metadata": {
        "id": "bwkP2qIpqcol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = len(label_encoder.classes_)\n",
        "model = MultiModalEventClassifier(config, num_labels, auxiliary_feature_size=auxiliary_features.shape[1])\n",
        "model.to(config.device)\n",
        "\n",
        "# Model info\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# Optimizer and scheduler\n",
        "optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
        "total_steps = len(train_loader) * config.num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=config.warmup_steps, num_training_steps=total_steps)\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=config.label_smoothing)\n",
        "\n",
        "# Training loop\n",
        "print(\"\\nStarting training...\")\n",
        "train_losses, train_accs = [], []\n",
        "val_losses, val_accs = [], []\n",
        "best_accuracy = 0\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(config.num_epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{config.num_epochs}\")\n",
        "\n",
        "    # Train\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, scheduler, criterion, config.device)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "\n",
        "    # Evaluate\n",
        "    val_loss, val_acc, _, _ = evaluate(model, val_loader, criterion, config.device)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_accuracy:\n",
        "        best_accuracy = val_acc\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= config.early_stopping_patience:\n",
        "        print(f\"Early stopping at epoch {epoch + 1}\")\n",
        "        break\n",
        "\n",
        "print(f\"\\n✓ Training complete! Best accuracy: {best_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "0eRR1AEYqflI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accs, label='Train Accuracy')\n",
        "plt.plot(val_accs, label='Val Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vJ7bSFYZqk-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# Final evaluation\n",
        "val_loss, val_acc, predictions, true_labels = evaluate(model, val_loader, criterion, config.device)\n",
        "\n",
        "print(f\"Final Validation Accuracy: {val_acc:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_labels, predictions, target_names=label_encoder.classes_))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(true_labels, predictions)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=label_encoder.classes_,\n",
        "            yticklabels=label_encoder.classes_, cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sEXqvnoFq465"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'label_encoder_classes': label_encoder.classes_,\n",
        "    'emotion_encoder_classes': aux_extractor.emotion_encoder.classes_,\n",
        "    'tense_encoder_classes': aux_extractor.tense_encoder.classes_,\n",
        "    'scaler_mean': aux_extractor.scaler.mean_,\n",
        "    'scaler_scale': aux_extractor.scaler.scale_,\n",
        "    'config': config,\n",
        "    'best_accuracy': best_accuracy\n",
        "}, 'event_classifier_complete.pth')\n",
        "\n",
        "print(\"✓ Model saved as 'event_classifier_complete.pth'\")"
      ],
      "metadata": {
        "id": "i7J4YmYFq_Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_event(text, model, tokenizer, label_encoder, aux_extractor=None,\n",
        "                  auxiliary_data=None, device='cpu'):\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize\n",
        "    encoding = tokenizer(text, truncation=True, padding='max_length',\n",
        "                        max_length=config.max_length, return_tensors='pt')\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    # Handle auxiliary features - ALWAYS provide them\n",
        "    if aux_extractor is not None:\n",
        "        if auxiliary_data is None:\n",
        "            # Create default auxiliary data when not provided\n",
        "            auxiliary_data = {\n",
        "                'SENTIMENT_VALENCE': 0.5,  # neutral sentiment\n",
        "                'EMOTION': 'neutral',\n",
        "                'SARCASM': 'FALSE',\n",
        "                'TENSE': 'present',\n",
        "                'CERTAINTY': 0.5,\n",
        "                'GENERATED': 'TRUE'\n",
        "            }\n",
        "        aux_df = pd.DataFrame([auxiliary_data])\n",
        "        auxiliary_features = torch.tensor(\n",
        "            aux_extractor.transform(aux_df), dtype=torch.float\n",
        "        ).to(device)\n",
        "    else:\n",
        "        # This should not happen in normal use, but just in case\n",
        "        raise ValueError(\"aux_extractor is required for predictions\")\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask,\n",
        "                       auxiliary_features=auxiliary_features)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "        prediction = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    predicted_event = label_encoder.inverse_transform(prediction.cpu().numpy())[0]\n",
        "    confidence = probabilities[0, prediction[0]].item()\n",
        "\n",
        "    # Top 3 predictions\n",
        "    top_probs, top_indices = torch.topk(probabilities[0], 3)\n",
        "    top_predictions = [(label_encoder.inverse_transform([idx.item()])[0], prob.item())\n",
        "                      for idx, prob in zip(top_indices, top_probs)]\n",
        "\n",
        "    return {\n",
        "        'predicted_event': predicted_event,\n",
        "        'confidence': confidence,\n",
        "        'top_predictions': top_predictions\n",
        "    }\n",
        "\n",
        "print(\"✓ Inference function defined\")"
      ],
      "metadata": {
        "id": "lHvRfT_IrDv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_examples = [\n",
        "    {\n",
        "        'text': \"I just got promoted to senior manager!\",\n",
        "        'aux': {'SENTIMENT_VALENCE': 0.9, 'EMOTION': 'joy', 'SARCASM': 'FALSE',\n",
        "                'TENSE': 'past', 'CERTAINTY': 1.0, 'GENERATED': 'TRUE'}\n",
        "    },\n",
        "    {\n",
        "        'text': \"They laid me off after 10 years with the company\",\n",
        "        'aux': {'SENTIMENT_VALENCE': 0.1, 'EMOTION': 'sadness', 'SARCASM': 'FALSE',\n",
        "                'TENSE': 'past', 'CERTAINTY': 1.0, 'GENERATED': 'TRUE'}\n",
        "    },\n",
        "    {\n",
        "        'text': \"Starting my freelance journey next month!\",\n",
        "        'aux': {'SENTIMENT_VALENCE': 0.8, 'EMOTION': 'hope', 'SARCASM': 'FALSE',\n",
        "                'TENSE': 'future', 'CERTAINTY': 0.9, 'GENERATED': 'TRUE'}\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"Testing predictions:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i, example in enumerate(test_examples, 1):\n",
        "    result = predict_event(example['text'], model, tokenizer, label_encoder,\n",
        "                          aux_extractor, example['aux'], config.device)\n",
        "\n",
        "    print(f\"\\nExample {i}: \\\"{example['text']}\\\"\")\n",
        "    print(f\"Predicted: {result['predicted_event']} (confidence: {result['confidence']:.2%})\")\n",
        "    print(f\"Top 3 predictions:\")\n",
        "    for event, prob in result['top_predictions']:\n",
        "        print(f\"  - {event}: {prob:.2%}\")\n",
        "\n",
        "# Test without auxiliary features\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Testing without auxiliary features (using defaults):\")\n",
        "\n",
        "simple_text = \"I can't believe they fired me today\"\n",
        "# Pass aux_extractor but no auxiliary_data - it will use defaults\n",
        "result = predict_event(simple_text, model, tokenizer, label_encoder,\n",
        "                      aux_extractor, None, config.device)\n",
        "print(f\"\\nText: \\\"{simple_text}\\\"\")\n",
        "print(f\"Predicted: {result['predicted_event']} ({result['confidence']:.2%})\")\n",
        "\n",
        "# More test examples\n",
        "print(\"\\nAdditional examples (with default auxiliary features):\")\n",
        "more_examples = [\n",
        "    \"Just got a raise after my annual review!\",\n",
        "    \"I'm being terminated effective immediately\",\n",
        "    \"Starting as a freelancer next week\",\n",
        "    \"Received employee of the year award\"\n",
        "]\n",
        "\n",
        "for text in more_examples:\n",
        "    result = predict_event(text, model, tokenizer, label_encoder,\n",
        "                          aux_extractor, None, config.device)\n",
        "    print(f\"\\n\\\"{text}\\\"\")\n",
        "    print(f\"→ {result['predicted_event']} ({result['confidence']:.2%})\")"
      ],
      "metadata": {
        "id": "2Xp_1UcirHaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 18: Test with Balanced Real-Life Examples\n",
        "\"\"\"\n",
        "Test the model with realistic but clearer examples\n",
        "\"\"\"\n",
        "balanced_examples = [\n",
        "    # Promotions - clear but natural\n",
        "    {\n",
        "        'text': \"Just got the call - I'm the new VP of Sales! Can't believe it!\",\n",
        "        'expected': 'got_promoted'\n",
        "    },\n",
        "    {\n",
        "        'text': \"Moving up to team lead position next month. Nervous but excited!\",\n",
        "        'expected': 'got_promoted'\n",
        "    },\n",
        "\n",
        "    # Getting fired - direct but realistic\n",
        "    {\n",
        "        'text': \"HR just told me today is my last day. Still in shock.\",\n",
        "        'expected': 'got_fired'\n",
        "    },\n",
        "    {\n",
        "        'text': \"They terminated my contract. No warning, just done.\",\n",
        "        'expected': 'got_fired'\n",
        "    },\n",
        "\n",
        "    # Layoffs - clear context\n",
        "    {\n",
        "        'text': \"Our entire division got laid off due to budget cuts. 200 people gone.\",\n",
        "        'expected': 'got_laid_off'\n",
        "    },\n",
        "    {\n",
        "        'text': \"Company downsizing hit us hard. Got my severance package today.\",\n",
        "        'expected': 'got_laid_off'\n",
        "    },\n",
        "\n",
        "    # Freelancing - obvious transition\n",
        "    {\n",
        "        'text': \"Quit my job to start freelancing full-time. First client meeting tomorrow!\",\n",
        "        'expected': 'became_freelancer'\n",
        "    },\n",
        "    {\n",
        "        'text': \"Finally took the leap into freelance consulting. No more office politics!\",\n",
        "        'expected': 'became_freelancer'\n",
        "    },\n",
        "\n",
        "    # Starting business\n",
        "    {\n",
        "        'text': \"Registered my LLC today! My side project is now my main business.\",\n",
        "        'expected': 'started_business'\n",
        "    },\n",
        "    {\n",
        "        'text': \"Left corporate to launch my startup. Scary but it's now or never.\",\n",
        "        'expected': 'started_business'\n",
        "    },\n",
        "\n",
        "    # Job changes\n",
        "    {\n",
        "        'text': \"Last day at ABC Corp, starting at XYZ Inc on Monday!\",\n",
        "        'expected': 'changed_jobs'\n",
        "    },\n",
        "    {\n",
        "        'text': \"Accepted an offer from a competitor. Better pay and growth opportunities.\",\n",
        "        'expected': 'changed_jobs'\n",
        "    },\n",
        "\n",
        "    # Getting hired\n",
        "    {\n",
        "        'text': \"I GOT THE JOB! Starting as a developer at Google next month!\",\n",
        "        'expected': 'got_hired'\n",
        "    },\n",
        "    {\n",
        "        'text': \"After 6 months of searching, finally got hired! Marketing manager role.\",\n",
        "        'expected': 'got_hired'\n",
        "    },\n",
        "\n",
        "    # Raise and pay cuts\n",
        "    {\n",
        "        'text': \"Annual review went great - 15% raise effective immediately!\",\n",
        "        'expected': 'got_raise'\n",
        "    },\n",
        "    {\n",
        "        'text': \"Company announced 10% salary reduction across the board. This hurts.\",\n",
        "        'expected': 'got_pay_cut'\n",
        "    },\n",
        "\n",
        "    # Work issues\n",
        "    {\n",
        "        'text': \"Got written up for being late three times this month. Need to do better.\",\n",
        "        'expected': 'got_late_to_work'\n",
        "    },\n",
        "    {\n",
        "        'text': \"Missed the client deadline and the boss is furious. Major mistake.\",\n",
        "        'expected': 'missed_deadline'\n",
        "    },\n",
        "\n",
        "    # Workplace harassment\n",
        "    {\n",
        "        'text': \"Filed a complaint with HR about my manager's inappropriate comments.\",\n",
        "        'expected': 'workplace_harassment'\n",
        "    },\n",
        "    {\n",
        "        'text': \"Being bullied at work is affecting my mental health. Considering options.\",\n",
        "        'expected': 'workplace_harassment'\n",
        "    },\n",
        "\n",
        "    # Awards and recognition\n",
        "    {\n",
        "        'text': \"Won employee of the quarter! Hard work really does pay off.\",\n",
        "        'expected': 'got_work_award'\n",
        "    },\n",
        "    {\n",
        "        'text': \"Received the innovation award at the company ceremony last night!\",\n",
        "        'expected': 'got_work_award'\n",
        "    },\n",
        "\n",
        "    # Retirement\n",
        "    {\n",
        "        'text': \"After 35 years, I'm officially retiring next Friday. What a journey!\",\n",
        "        'expected': 'retired'\n",
        "    },\n",
        "    {\n",
        "        'text': \"Submitted my retirement papers. 6 more weeks and I'm done!\",\n",
        "        'expected': 'retired'\n",
        "    },\n",
        "\n",
        "    # Business failure\n",
        "    {\n",
        "        'text': \"Had to shut down the business. Ran out of funding and customers.\",\n",
        "        'expected': 'business_failed'\n",
        "    },\n",
        "    {\n",
        "        'text': \"My startup didn't make it. Back to the job market I go.\",\n",
        "        'expected': 'business_failed'\n",
        "    },\n",
        "\n",
        "    # Sabbatical\n",
        "    {\n",
        "        'text': \"Taking a 6-month sabbatical to travel and recharge. Company approved!\",\n",
        "        'expected': 'got_sabbatical'\n",
        "    },\n",
        "    {\n",
        "        'text': \"Unpaid leave starting next month. Need time to focus on family.\",\n",
        "        'expected': 'got_sabbatical'\n",
        "    },\n",
        "\n",
        "    # New career\n",
        "    {\n",
        "        'text': \"Left engineering to become a teacher. Completely new career at 40!\",\n",
        "        'expected': 'started_new_career'\n",
        "    },\n",
        "    {\n",
        "        'text': \"From lawyer to chef - following my passion finally!\",\n",
        "        'expected': 'started_new_career'\n",
        "    },\n",
        "\n",
        "    # Demotion\n",
        "    {\n",
        "        'text': \"They moved me back to analyst role. No longer managing the team.\",\n",
        "        'expected': 'got_demoted'\n",
        "    },\n",
        "    {\n",
        "        'text': \"Lost my senior title after the merger. Pretty disappointed.\",\n",
        "        'expected': 'got_demoted'\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"Testing balanced real-life examples:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "correct = 0\n",
        "total = len(balanced_examples)\n",
        "\n",
        "for i, example in enumerate(balanced_examples, 1):\n",
        "    result = predict_event(example['text'], model, tokenizer, label_encoder,\n",
        "                          aux_extractor, None, config.device)\n",
        "\n",
        "    predicted = result['predicted_event']\n",
        "    expected = example['expected']\n",
        "    is_correct = predicted == expected\n",
        "    if is_correct:\n",
        "        correct += 1\n",
        "\n",
        "    print(f\"\\n{i}. \\\"{example['text']}\\\"\")\n",
        "    print(f\"   Expected: {expected}\")\n",
        "    print(f\"   Predicted: {predicted} ({result['confidence']:.1%}) {'✓' if is_correct else '✗'}\")\n",
        "\n",
        "    if not is_correct and result['confidence'] < 0.8:\n",
        "        print(f\"   Top 3:\")\n",
        "        for event, prob in result['top_predictions']:\n",
        "            print(f\"     - {event}: {prob:.1%}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"Accuracy on balanced examples: {correct}/{total} ({correct/total*100:.1f}%)\")\n",
        "\n",
        "# Test a few edge cases\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"Testing edge cases:\")\n",
        "\n",
        "edge_cases = [\n",
        "    \"Promotion without a raise - still grateful for the opportunity though!\",\n",
        "    \"They're letting me go but calling it 'mutual separation'\",\n",
        "    \"Is it really freelancing if I only have one client who used to be my employer?\",\n",
        "    \"Got demoted but keeping the same salary, so mixed feelings\",\n",
        "    \"Won an award but it came with mandatory overtime\",\n",
        "]\n",
        "\n",
        "for text in edge_cases:\n",
        "    result = predict_event(text, model, tokenizer, label_encoder,\n",
        "                          aux_extractor, None, config.device)\n",
        "    print(f\"\\n\\\"{text}\\\"\")\n",
        "    print(f\"→ {result['predicted_event']} ({result['confidence']:.1%})\")"
      ],
      "metadata": {
        "id": "3b9xmmzs0ZSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 19: Enhanced Multi-Event Prediction\n",
        "\"\"\"\n",
        "Prediction function that returns multiple events for ambiguous cases\n",
        "\"\"\"\n",
        "def predict_event_multi(text, model, tokenizer, label_encoder, aux_extractor=None,\n",
        "                       auxiliary_data=None, device='cpu', certainty_threshold=0.8):\n",
        "    \"\"\"\n",
        "    Predicts potentially multiple events when certainty is below threshold.\n",
        "    Returns events until cumulative certainty exceeds threshold.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize\n",
        "    encoding = tokenizer(text, truncation=True, padding='max_length',\n",
        "                        max_length=config.max_length, return_tensors='pt')\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    # Handle auxiliary features\n",
        "    if aux_extractor is not None:\n",
        "        if auxiliary_data is None:\n",
        "            auxiliary_data = {\n",
        "                'SENTIMENT_VALENCE': 0.5,\n",
        "                'EMOTION': 'neutral',\n",
        "                'SARCASM': 'FALSE',\n",
        "                'TENSE': 'present',\n",
        "                'CERTAINTY': 0.5,\n",
        "                'GENERATED': 'TRUE'\n",
        "            }\n",
        "        aux_df = pd.DataFrame([auxiliary_data])\n",
        "        auxiliary_features = torch.tensor(\n",
        "            aux_extractor.transform(aux_df), dtype=torch.float\n",
        "        ).to(device)\n",
        "    else:\n",
        "        raise ValueError(\"aux_extractor is required for predictions\")\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask,\n",
        "                       auxiliary_features=auxiliary_features)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "    # Get all predictions sorted by probability\n",
        "    probs, indices = torch.sort(probabilities[0], descending=True)\n",
        "\n",
        "    # Convert to list of (event, certainty) tuples\n",
        "    all_predictions = [(label_encoder.inverse_transform([idx.item()])[0], prob.item())\n",
        "                      for idx, prob in zip(indices, probs)]\n",
        "\n",
        "    # Determine primary event and certainty\n",
        "    primary_event = all_predictions[0][0]\n",
        "    primary_certainty = all_predictions[0][1]\n",
        "\n",
        "    # If certainty is high enough, return single event\n",
        "    if primary_certainty >= certainty_threshold:\n",
        "        return {\n",
        "            'events': [primary_event],\n",
        "            'certainties': [primary_certainty],\n",
        "            'combined_certainty': primary_certainty,\n",
        "            'interpretation': f\"Clear single event: {primary_event}\"\n",
        "        }\n",
        "\n",
        "    # Otherwise, accumulate events until threshold is met\n",
        "    selected_events = []\n",
        "    selected_certainties = []\n",
        "    cumulative_certainty = 0.0\n",
        "\n",
        "    for event, certainty in all_predictions:\n",
        "        if cumulative_certainty >= certainty_threshold:\n",
        "            break\n",
        "        selected_events.append(event)\n",
        "        selected_certainties.append(certainty)\n",
        "        cumulative_certainty += certainty * (1 - cumulative_certainty)  # Diminishing returns\n",
        "\n",
        "        # Stop at 3 events max for clarity\n",
        "        if len(selected_events) >= 3:\n",
        "            break\n",
        "\n",
        "    # Create interpretation\n",
        "    if len(selected_events) == 1:\n",
        "        interpretation = f\"Likely {selected_events[0]} but with some uncertainty\"\n",
        "    elif len(selected_events) == 2:\n",
        "        interpretation = f\"Could be {selected_events[0]} or {selected_events[1]}\"\n",
        "    else:\n",
        "        interpretation = f\"Multiple possible events: {', '.join(selected_events[:2])} or others\"\n",
        "\n",
        "    return {\n",
        "        'events': selected_events,\n",
        "        'certainties': selected_certainties,\n",
        "        'combined_certainty': cumulative_certainty,\n",
        "        'interpretation': interpretation\n",
        "    }\n",
        "\n",
        "# Test the multi-event prediction\n",
        "print(\"Testing multi-event predictions on ambiguous cases:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "ambiguous_examples = [\n",
        "    # Clear cases (should return single event)\n",
        "    \"I got fired yesterday. Still processing it.\",\n",
        "    \"Promoted to Director level! Dream come true!\",\n",
        "\n",
        "    # Multi-event cases\n",
        "    \"Left my job for a better position at a competitor with 30% more pay\",\n",
        "    \"They promoted me but I'm still doing my old job too with no raise\",\n",
        "    \"Company shut down so I'm freelancing with my former clients\",\n",
        "    \"Got the award but they also cut my hours\",\n",
        "    \"Quit to start my own consulting firm\",\n",
        "    \"The restructuring meant I lost my team but kept my title\",\n",
        "    \"New job starts Monday - less money but better work-life balance\",\n",
        "    \"They're calling it a sabbatical but we all know I'm not coming back\",\n",
        "    \"Performance review was bad, lost my bonus and got a warning\",\n",
        "    \"Accepted the severance package and already have interviews lined up\"\n",
        "]\n",
        "\n",
        "for text in ambiguous_examples:\n",
        "    result = predict_event_multi(text, model, tokenizer, label_encoder,\n",
        "                                aux_extractor, None, config.device,\n",
        "                                certainty_threshold=0.8)\n",
        "\n",
        "    print(f\"\\n\\\"{text}\\\"\")\n",
        "    if len(result['events']) == 1:\n",
        "        print(f\"→ {result['events'][0]} (certainty: {result['certainties'][0]:.2f})\")\n",
        "    else:\n",
        "        print(f\"→ Multiple events detected:\")\n",
        "        for event, cert in zip(result['events'], result['certainties']):\n",
        "            print(f\"   - {event}: {cert:.2f}\")\n",
        "        print(f\"   Combined certainty: {result['combined_certainty']:.2f}\")\n",
        "    print(f\"   Interpretation: {result['interpretation']}\")\n",
        "\n",
        "# Create a summary comparison\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"Comparison of single vs multi-event predictions:\")\n",
        "\n",
        "comparison_texts = [\n",
        "    \"Accepted offer from competitor with better pay and growth\",\n",
        "    \"Promotion without raise - still grateful though\",\n",
        "    \"Started freelancing after the layoff\"\n",
        "]\n",
        "\n",
        "for text in comparison_texts:\n",
        "    # Single prediction\n",
        "    single = predict_event(text, model, tokenizer, label_encoder,\n",
        "                          aux_extractor, None, config.device)\n",
        "\n",
        "    # Multi prediction\n",
        "    multi = predict_event_multi(text, model, tokenizer, label_encoder,\n",
        "                               aux_extractor, None, config.device, 0.8)\n",
        "\n",
        "    print(f\"\\n\\\"{text}\\\"\")\n",
        "    print(f\"Single: {single['predicted_event']} ({single['confidence']:.1%})\")\n",
        "    print(f\"Multi:  {' + '.join(multi['events'])} (combined: {multi['combined_certainty']:.2f})\")"
      ],
      "metadata": {
        "id": "PqEFQKC41tNX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}