{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMAAhMS+wCxq4Gm3KaP/9xp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kishan-prajapati-242/ATCTM/blob/main/notebooks/EC_demo_8_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtL3wg8khwwP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import json\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"‚úì All libraries imported successfully!\")\n",
        "print(f\"‚úì PyTorch version: {torch.__version__}\")\n",
        "print(f\"‚úì Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
        "\n",
        "\n",
        "class Config:\n",
        "    # Model\n",
        "    model_name = 'microsoft/deberta-v3-base'\n",
        "    max_length = 256\n",
        "\n",
        "    # Training\n",
        "    batch_size = 16\n",
        "    learning_rate = 2e-5\n",
        "    num_epochs = 20\n",
        "    warmup_steps = 500\n",
        "    weight_decay = 0.01\n",
        "\n",
        "    # Architecture\n",
        "    hidden_dim = 768\n",
        "    num_attention_heads = 12\n",
        "    dropout_rate = 0.3\n",
        "    label_smoothing = 0.1\n",
        "\n",
        "    # Multi-task loss weights\n",
        "    task_weights = {\n",
        "        'event_type': 1.0,      # Primary task\n",
        "        'event_group': 0.8,\n",
        "        'sentiment_valence': 0.6,\n",
        "        'emotion': 0.7,\n",
        "        'sarcasm': 0.5,\n",
        "        'tense': 0.5,\n",
        "        'certainty': 0.5\n",
        "    }\n",
        "\n",
        "    # Training strategy\n",
        "    gradient_accumulation_steps = 2\n",
        "    max_grad_norm = 1.0\n",
        "    early_stopping_patience = 5\n",
        "\n",
        "    # Multi-event threshold\n",
        "    multi_event_threshold = 0.7\n",
        "\n",
        "    # Device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Save paths\n",
        "    save_dir = '/content/drive/MyDrive/EC-model-v2'\n",
        "\n",
        "config = Config()\n",
        "print(f\"Configuration loaded. Device: {config.device}\")\n",
        "\n",
        "# Create save directory\n",
        "os.makedirs(config.save_dir, exist_ok=True)\n",
        "print(f\"Save directory: {config.save_dir}\")\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/ATCTM/EVENT_CLASSIFICATION/EC-demo.csv')\n",
        "print(f\"Dataset loaded: {len(df)} samples\")\n",
        "\n",
        "# Data analysis\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "print(\"Data types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Fix boolean columns if needed\n",
        "if df['SARCASM'].dtype == 'bool':\n",
        "    df['SARCASM'] = df['SARCASM'].map({True: 'TRUE', False: 'FALSE'})\n",
        "    print(\"Converted SARCASM from bool to string\")\n",
        "\n",
        "if 'GENERATED' in df.columns and df['GENERATED'].dtype == 'bool':\n",
        "    df['GENERATED'] = df['GENERATED'].map({True: 'TRUE', False: 'FALSE'})\n",
        "    print(\"Converted GENERATED from bool to string\")\n",
        "\n",
        "# Show distribution\n",
        "print(\"\\nEvent type distribution:\")\n",
        "print(df['EVENT_TYPE'].value_counts().head(10))\n",
        "\n",
        "# import pandas as pd\n",
        "\n",
        "# # Load only first 200 rows\n",
        "# df = pd.read_csv('/content/drive/MyDrive/ATCTM/EVENT_CLASSIFICATION/EC-demo.csv').head(400)\n",
        "# print(f\"Dataset loaded: {len(df)} samples\")\n",
        "\n",
        "# # Data analysis\n",
        "# print(\"\\nMissing values:\")\n",
        "# print(df.isnull().sum())\n",
        "# print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# print(\"Data types:\")\n",
        "# print(df.dtypes)\n",
        "# print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# # Fix boolean columns if needed\n",
        "# if df['SARCASM'].dtype == 'bool':\n",
        "#     df['SARCASM'] = df['SARCASM'].map({True: 'TRUE', False: 'FALSE'})\n",
        "#     print(\"Converted SARCASM from bool to string\")\n",
        "\n",
        "# if 'GENERATED' in df.columns and df['GENERATED'].dtype == 'bool':\n",
        "#     df['GENERATED'] = df['GENERATED'].map({True: 'TRUE', False: 'FALSE'})\n",
        "#     print(\"Converted GENERATED from bool to string\")\n",
        "\n",
        "# # Show distribution\n",
        "# print(\"\\nEvent type distribution:\")\n",
        "# print(df['EVENT_TYPE'].value_counts().head(10))\n",
        "\n",
        "\n",
        "class MultiTaskLabelEncoders:\n",
        "    def __init__(self):\n",
        "        self.encoders = {}\n",
        "        self.num_classes = {}\n",
        "\n",
        "    def fit(self, df):\n",
        "        # EVENT_TYPE encoder\n",
        "        self.encoders['event_type'] = LabelEncoder()\n",
        "        self.encoders['event_type'].fit(df['EVENT_TYPE'])\n",
        "        self.num_classes['event_type'] = len(self.encoders['event_type'].classes_)\n",
        "\n",
        "        # EVENT_GROUP encoder\n",
        "        self.encoders['event_group'] = LabelEncoder()\n",
        "        self.encoders['event_group'].fit(df['EVENT_GROUP'])\n",
        "        self.num_classes['event_group'] = len(self.encoders['event_group'].classes_)\n",
        "\n",
        "        # EMOTION encoder\n",
        "        self.encoders['emotion'] = LabelEncoder()\n",
        "        self.encoders['emotion'].fit(df['EMOTION'].fillna('neutral'))\n",
        "        self.num_classes['emotion'] = len(self.encoders['emotion'].classes_)\n",
        "\n",
        "        # TENSE encoder (handle missing values)\n",
        "        tense_values = df['TENSE'].dropna().unique()\n",
        "        self.encoders['tense'] = LabelEncoder()\n",
        "        self.encoders['tense'].fit(tense_values)\n",
        "        self.num_classes['tense'] = len(self.encoders['tense'].classes_)\n",
        "\n",
        "        # Binary classification for SARCASM\n",
        "        self.num_classes['sarcasm'] = 2\n",
        "\n",
        "        print(f\"Encoders fitted:\")\n",
        "        for key, num in self.num_classes.items():\n",
        "            if key in self.encoders:\n",
        "                print(f\"  {key}: {num} classes - {list(self.encoders[key].classes_)[:5]}...\")\n",
        "            else:\n",
        "                print(f\"  {key}: {num} classes\")\n",
        "\n",
        "    def transform(self, value, task, default=None):\n",
        "        if task == 'sarcasm':\n",
        "            return 1 if str(value).upper() == 'TRUE' or value == True else 0\n",
        "        elif task in ['sentiment_valence', 'certainty']:\n",
        "            return float(value) if pd.notna(value) else 0.5\n",
        "        else:\n",
        "            if pd.isna(value):\n",
        "                if task == 'tense':\n",
        "                    value = 'present'  # Default for TENSE\n",
        "                elif task == 'emotion':\n",
        "                    value = 'neutral'  # Default for EMOTION\n",
        "                else:\n",
        "                    value = default if default else list(self.encoders[task].classes_)[0]\n",
        "            return self.encoders[task].transform([value])[0]\n",
        "\n",
        "    def inverse_transform(self, labels, task):\n",
        "        if task == 'sarcasm':\n",
        "            return ['FALSE' if l == 0 else 'TRUE' for l in labels]\n",
        "        elif task in ['sentiment_valence', 'certainty']:\n",
        "            return labels\n",
        "        else:\n",
        "            return self.encoders[task].inverse_transform(labels)\n",
        "\n",
        "# Initialize encoders\n",
        "label_encoders = MultiTaskLabelEncoders()\n",
        "label_encoders.fit(df)\n",
        "\n",
        "\n",
        "class MultiTaskEventDataset(Dataset):\n",
        "    def __init__(self, texts, labels_df, tokenizer, label_encoders, max_length=256):\n",
        "        self.texts = texts\n",
        "        self.labels_df = labels_df.reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label_encoders = label_encoders\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        row = self.labels_df.iloc[idx]\n",
        "\n",
        "        # Tokenize\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Get all labels\n",
        "        labels = {\n",
        "            'event_type': self.label_encoders.transform(row['EVENT_TYPE'], 'event_type'),\n",
        "            'event_group': self.label_encoders.transform(row['EVENT_GROUP'], 'event_group'),\n",
        "            'emotion': self.label_encoders.transform(row['EMOTION'], 'emotion'),\n",
        "            'tense': self.label_encoders.transform(row['TENSE'], 'tense'),\n",
        "            'sarcasm': self.label_encoders.transform(row['SARCASM'], 'sarcasm'),\n",
        "            'sentiment_valence': self.label_encoders.transform(row['SENTIMENT_VALENCE'], 'sentiment_valence'),\n",
        "            'certainty': self.label_encoders.transform(row['CERTAINTY'], 'certainty')\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "print(\"‚úì Dataset class defined\")\n",
        "\n",
        "\n",
        "class MultiTaskEventClassifier(nn.Module):\n",
        "    def __init__(self, config, label_encoders):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.label_encoders = label_encoders\n",
        "\n",
        "        # Load pre-trained transformer\n",
        "        self.transformer = AutoModel.from_pretrained(config.model_name)\n",
        "\n",
        "        # Freeze embeddings\n",
        "        for param in self.transformer.embeddings.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Attention for text features\n",
        "        self.text_attention = nn.MultiheadAttention(\n",
        "            embed_dim=self.transformer.config.hidden_size,\n",
        "            num_heads=config.num_attention_heads,\n",
        "            dropout=config.dropout_rate,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Shared feature extractor\n",
        "        self.shared_layer = nn.Sequential(\n",
        "            nn.Linear(self.transformer.config.hidden_size, config.hidden_dim),\n",
        "            nn.LayerNorm(config.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(config.dropout_rate)\n",
        "        )\n",
        "\n",
        "        # Task-specific classifiers\n",
        "        self.event_type_classifier = self._make_classifier(\n",
        "            config.hidden_dim, label_encoders.num_classes['event_type'])\n",
        "        self.event_group_classifier = self._make_classifier(\n",
        "            config.hidden_dim, label_encoders.num_classes['event_group'])\n",
        "        self.emotion_classifier = self._make_classifier(\n",
        "            config.hidden_dim, label_encoders.num_classes['emotion'])\n",
        "        self.tense_classifier = self._make_classifier(\n",
        "            config.hidden_dim, label_encoders.num_classes['tense'])\n",
        "        self.sarcasm_classifier = self._make_classifier(\n",
        "            config.hidden_dim, 2)\n",
        "\n",
        "        # Regression heads\n",
        "        self.sentiment_regressor = self._make_regressor(config.hidden_dim)\n",
        "        self.certainty_regressor = self._make_regressor(config.hidden_dim)\n",
        "\n",
        "    def _make_classifier(self, input_dim, num_classes):\n",
        "        return nn.Sequential(\n",
        "            nn.Linear(input_dim, input_dim // 2),\n",
        "            nn.LayerNorm(input_dim // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(self.config.dropout_rate),\n",
        "            nn.Linear(input_dim // 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def _make_regressor(self, input_dim):\n",
        "        return nn.Sequential(\n",
        "            nn.Linear(input_dim, input_dim // 2),\n",
        "            nn.LayerNorm(input_dim // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(self.config.dropout_rate),\n",
        "            nn.Linear(input_dim // 2, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Get transformer outputs\n",
        "        outputs = self.transformer(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        # Apply attention\n",
        "        hidden_state = outputs.last_hidden_state\n",
        "        attended, _ = self.text_attention(\n",
        "            hidden_state, hidden_state, hidden_state,\n",
        "            key_padding_mask=~attention_mask.bool()\n",
        "        )\n",
        "\n",
        "        # Pool\n",
        "        text_features = (attended * attention_mask.unsqueeze(-1)).sum(dim=1) / attention_mask.sum(dim=1, keepdim=True)\n",
        "\n",
        "        # Get shared features\n",
        "        shared_features = self.shared_layer(text_features)\n",
        "\n",
        "        # Get predictions from each head\n",
        "        outputs = {\n",
        "            'event_type': self.event_type_classifier(shared_features),\n",
        "            'event_group': self.event_group_classifier(shared_features),\n",
        "            'emotion': self.emotion_classifier(shared_features),\n",
        "            'tense': self.tense_classifier(shared_features),\n",
        "            'sarcasm': self.sarcasm_classifier(shared_features),\n",
        "            'sentiment_valence': self.sentiment_regressor(shared_features).squeeze(-1),\n",
        "            'certainty': self.certainty_regressor(shared_features).squeeze(-1)\n",
        "        }\n",
        "\n",
        "        return outputs\n",
        "\n",
        "print(\"‚úì Model architecture defined\")\n",
        "\n",
        "class MultiTaskLoss(nn.Module):\n",
        "    def __init__(self, config, label_smoothing=0.1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.ce_loss = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "\n",
        "    def forward(self, outputs, labels):\n",
        "        losses = {}\n",
        "\n",
        "        # Classification losses\n",
        "        for task in ['event_type', 'event_group', 'emotion', 'tense', 'sarcasm']:\n",
        "            losses[task] = self.ce_loss(outputs[task], labels[task])\n",
        "\n",
        "        # Regression losses\n",
        "        for task in ['sentiment_valence', 'certainty']:\n",
        "            losses[task] = self.mse_loss(outputs[task], labels[task].float())\n",
        "\n",
        "        # Weighted sum\n",
        "        total_loss = sum(\n",
        "            self.config.task_weights.get(task, 1.0) * loss\n",
        "            for task, loss in losses.items()\n",
        "        )\n",
        "\n",
        "        return total_loss, losses\n",
        "\n",
        "print(\"‚úì Loss function defined\")\n",
        "\n",
        "def train_epoch(model, dataloader, optimizer, scheduler, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    task_losses = {task: 0 for task in config.task_weights.keys()}\n",
        "\n",
        "    for batch in tqdm(dataloader, desc='Training'):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        # Convert labels to tensors\n",
        "        labels = {}\n",
        "        for key, value in batch['labels'].items():\n",
        "            if isinstance(value, list):\n",
        "                labels[key] = torch.tensor(value, device=device)\n",
        "            else:\n",
        "                labels[key] = value.to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss, losses = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        for task, task_loss in losses.items():\n",
        "            task_losses[task] += task_loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    avg_task_losses = {k: v / len(dataloader) for k, v in task_losses.items()}\n",
        "\n",
        "    return avg_loss, avg_task_losses\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    predictions = {task: [] for task in config.task_weights.keys()}\n",
        "    true_labels = {task: [] for task in config.task_weights.keys()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc='Evaluating'):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            labels = {}\n",
        "            for key, value in batch['labels'].items():\n",
        "                if isinstance(value, list):\n",
        "                    labels[key] = torch.tensor(value, device=device)\n",
        "                else:\n",
        "                    labels[key] = value.to(device)\n",
        "                true_labels[key].extend(labels[key].cpu().numpy())\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss, _ = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Get predictions\n",
        "            for task in ['event_type', 'event_group', 'emotion', 'tense', 'sarcasm']:\n",
        "                preds = torch.argmax(outputs[task], dim=1)\n",
        "                predictions[task].extend(preds.cpu().numpy())\n",
        "\n",
        "            for task in ['sentiment_valence', 'certainty']:\n",
        "                predictions[task].extend(outputs[task].cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracies = {}\n",
        "    for task in ['event_type', 'event_group', 'emotion', 'tense', 'sarcasm']:\n",
        "        accuracies[task] = accuracy_score(true_labels[task], predictions[task])\n",
        "\n",
        "    mse_scores = {}\n",
        "    for task in ['sentiment_valence', 'certainty']:\n",
        "        mse_scores[task] = mean_squared_error(true_labels[task], predictions[task])\n",
        "\n",
        "    return total_loss / len(dataloader), accuracies, mse_scores, predictions, true_labels\n",
        "\n",
        "print(\"‚úì Training functions defined\")\n",
        "\n",
        "train_indices, val_indices = train_test_split(\n",
        "    range(len(df)), test_size=0.2, random_state=42,\n",
        "    stratify=df['EVENT_TYPE']\n",
        ")\n",
        "\n",
        "train_texts = df.iloc[train_indices]['TEXT'].values\n",
        "val_texts = df.iloc[val_indices]['TEXT'].values\n",
        "train_labels = df.iloc[train_indices]\n",
        "val_labels = df.iloc[val_indices]\n",
        "\n",
        "print(f\"Training samples: {len(train_texts)}\")\n",
        "print(f\"Validation samples: {len(val_texts)}\")\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = MultiTaskEventDataset(train_texts, train_labels, tokenizer, label_encoders, config.max_length)\n",
        "val_dataset = MultiTaskEventDataset(val_texts, val_labels, tokenizer, label_encoders, config.max_length)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"‚úì DataLoaders created\")\n",
        "print(f\"  - Train batches: {len(train_loader)}\")\n",
        "print(f\"  - Val batches: {len(val_loader)}\")\n",
        "\n",
        "\n",
        "model = MultiTaskEventClassifier(config, label_encoders)\n",
        "model.to(config.device)\n",
        "\n",
        "# Model info\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# Optimizer and scheduler\n",
        "optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
        "total_steps = len(train_loader) * config.num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=config.warmup_steps, num_training_steps=total_steps)\n",
        "criterion = MultiTaskLoss(config, label_smoothing=config.label_smoothing)\n",
        "\n",
        "print(\"‚úì Model initialized\")\n",
        "\n",
        "# Cell 9 REPLACEMENT - Fix DataLoader Issues\n",
        "# Split data\n",
        "train_indices, val_indices = train_test_split(\n",
        "    range(len(df)), test_size=0.2, random_state=42,\n",
        "    stratify=df['EVENT_TYPE']\n",
        ")\n",
        "\n",
        "train_texts = df.iloc[train_indices]['TEXT'].values\n",
        "val_texts = df.iloc[val_indices]['TEXT'].values\n",
        "train_labels = df.iloc[train_indices]\n",
        "val_labels = df.iloc[val_indices]\n",
        "\n",
        "print(f\"Training samples: {len(train_texts)}\")\n",
        "print(f\"Validation samples: {len(val_texts)}\")\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = MultiTaskEventDataset(train_texts, train_labels, tokenizer, label_encoders, config.max_length)\n",
        "val_dataset = MultiTaskEventDataset(val_texts, val_labels, tokenizer, label_encoders, config.max_length)\n",
        "\n",
        "# Create dataloaders with num_workers=0 to avoid hanging\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,  # THIS IS THE KEY FIX\n",
        "    pin_memory=False  # Also disable pin_memory\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,  # THIS IS THE KEY FIX\n",
        "    pin_memory=False\n",
        ")\n",
        "\n",
        "print(f\"‚úì DataLoaders created (num_workers=0)\")\n",
        "print(f\"  - Train batches: {len(train_loader)}\")\n",
        "print(f\"  - Val batches: {len(val_loader)}\")\n",
        "\n",
        "# %%\n",
        "# Cell 11 REPLACEMENT - Simple Working Training Loop\n",
        "import gc\n",
        "import sys\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "train_losses, val_losses = [], []\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(config.num_epochs):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Epoch {epoch + 1}/{config.num_epochs}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # TRAINING\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    num_batches = len(train_loader)\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        # Print progress immediately\n",
        "        sys.stdout.write(f'\\rTraining: {batch_idx+1}/{num_batches} [{(batch_idx+1)/num_batches*100:.1f}%]')\n",
        "        sys.stdout.flush()\n",
        "\n",
        "        # Get data\n",
        "        input_ids = batch['input_ids'].to(config.device)\n",
        "        attention_mask = batch['attention_mask'].to(config.device)\n",
        "\n",
        "        labels = {}\n",
        "        for key, value in batch['labels'].items():\n",
        "            labels[key] = value.to(config.device)\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss, _ = criterion(outputs, labels)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Free memory\n",
        "        del input_ids, attention_mask, labels, outputs, loss\n",
        "\n",
        "    avg_train_loss = total_loss / num_batches\n",
        "    train_losses.append(avg_train_loss)\n",
        "    print(f'\\nTrain Loss: {avg_train_loss:.4f}')\n",
        "\n",
        "    # EVALUATION\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    val_accuracies = {'event_type': 0, 'event_group': 0, 'emotion': 0, 'tense': 0, 'sarcasm': 0}\n",
        "    val_counts = {'event_type': 0, 'event_group': 0, 'emotion': 0, 'tense': 0, 'sarcasm': 0}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(val_loader):\n",
        "            sys.stdout.write(f'\\rEvaluating: {batch_idx+1}/{len(val_loader)} [{(batch_idx+1)/len(val_loader)*100:.1f}%]')\n",
        "            sys.stdout.flush()\n",
        "\n",
        "            input_ids = batch['input_ids'].to(config.device)\n",
        "            attention_mask = batch['attention_mask'].to(config.device)\n",
        "\n",
        "            labels = {}\n",
        "            for key, value in batch['labels'].items():\n",
        "                labels[key] = value.to(config.device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss, _ = criterion(outputs, labels)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracies\n",
        "            for task in ['event_type', 'event_group', 'emotion', 'tense', 'sarcasm']:\n",
        "                preds = torch.argmax(outputs[task], dim=1)\n",
        "                correct = (preds == labels[task]).sum().item()\n",
        "                val_accuracies[task] += correct\n",
        "                val_counts[task] += labels[task].size(0)\n",
        "\n",
        "            del input_ids, attention_mask, labels, outputs\n",
        "\n",
        "    # Calculate final metrics\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    for task in val_accuracies:\n",
        "        val_accuracies[task] = val_accuracies[task] / val_counts[task]\n",
        "\n",
        "    print(f'\\nVal Loss: {avg_val_loss:.4f}')\n",
        "    print('Val Accuracies:', {k: f'{v:.3f}' for k, v in val_accuracies.items()})\n",
        "\n",
        "    # Save checkpoint\n",
        "    checkpoint_path = os.path.join(config.save_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
        "    torch.save({\n",
        "        'epoch': epoch + 1,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'label_encoders': label_encoders,\n",
        "        'config': config,\n",
        "        'val_loss': avg_val_loss,\n",
        "        'val_accuracies': val_accuracies\n",
        "    }, checkpoint_path)\n",
        "    print(f'‚úì Saved checkpoint: {checkpoint_path}')\n",
        "\n",
        "    # Save best model\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'label_encoders': label_encoders,\n",
        "            'config': config,\n",
        "            'best_val_loss': best_val_loss\n",
        "        }, os.path.join(config.save_dir, 'best_model.pth'))\n",
        "        print('‚úì New best model saved!')\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    # Clear memory\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    if patience_counter >= config.early_stopping_patience:\n",
        "        print(f'\\nEarly stopping at epoch {epoch+1}')\n",
        "        break\n",
        "\n",
        "print(f'\\n‚úì Training complete! Best val loss: {best_val_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Cell 12: Plot Training History\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss', linewidth=2)\n",
        "plt.plot(val_losses, label='Val Loss', linewidth=2)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot accuracies if available\n",
        "if 'val_accuracies' in locals():\n",
        "    plt.subplot(1, 2, 2)\n",
        "    tasks = list(val_accuracies.keys())\n",
        "    values = list(val_accuracies.values())\n",
        "    plt.bar(tasks, values)\n",
        "    plt.xlabel('Task')\n",
        "    plt.ylabel('Validation Accuracy')\n",
        "    plt.title('Final Validation Accuracies')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.ylim(0, 1.0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(config.save_dir, 'training_history.png'))\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# Cell 13: Prediction Functions\n",
        "def predict_event(text, model, tokenizer, label_encoders, device='cpu'):\n",
        "    \"\"\"Single prediction function\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize\n",
        "    encoding = tokenizer(text, truncation=True, padding='max_length',\n",
        "                        max_length=config.max_length, return_tensors='pt')\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Get EVENT_TYPE predictions (primary task)\n",
        "        probabilities = torch.softmax(outputs['event_type'], dim=1)\n",
        "        prediction = torch.argmax(outputs['event_type'], dim=1)\n",
        "\n",
        "    predicted_event = label_encoders.inverse_transform(prediction.cpu().numpy(), 'event_type')[0]\n",
        "    confidence = probabilities[0, prediction[0]].item()\n",
        "\n",
        "    # Top 3 predictions for EVENT_TYPE\n",
        "    top_probs, top_indices = torch.topk(probabilities[0], 3)\n",
        "    top_predictions = [(label_encoders.inverse_transform([idx.item()], 'event_type')[0], prob.item())\n",
        "                      for idx, prob in zip(top_indices, top_probs)]\n",
        "\n",
        "    # Get other predictions\n",
        "    other_predictions = {}\n",
        "\n",
        "    # Classifications\n",
        "    for task in ['event_group', 'emotion', 'tense']:\n",
        "        task_probs = torch.softmax(outputs[task], dim=1)\n",
        "        task_pred = torch.argmax(outputs[task], dim=1)\n",
        "        other_predictions[task] = {\n",
        "            'prediction': label_encoders.inverse_transform(task_pred.cpu().numpy(), task)[0],\n",
        "            'confidence': task_probs[0, task_pred[0]].item()\n",
        "        }\n",
        "\n",
        "    # Sarcasm\n",
        "    sarcasm_probs = torch.softmax(outputs['sarcasm'], dim=1)\n",
        "    sarcasm_pred = torch.argmax(outputs['sarcasm'], dim=1)\n",
        "    other_predictions['sarcasm'] = {\n",
        "        'prediction': 'TRUE' if sarcasm_pred.item() == 1 else 'FALSE',\n",
        "        'confidence': sarcasm_probs[0, sarcasm_pred[0]].item()\n",
        "    }\n",
        "\n",
        "    # Regressions\n",
        "    for task in ['sentiment_valence', 'certainty']:\n",
        "        other_predictions[task] = outputs[task][0].item()\n",
        "\n",
        "    return {\n",
        "        'predicted_event': predicted_event,\n",
        "        'confidence': confidence,\n",
        "        'top_predictions': top_predictions,\n",
        "        'other_outputs': other_predictions\n",
        "    }\n",
        "\n",
        "def predict_event_multi(text, model, tokenizer, label_encoders, device='cpu', certainty_threshold=0.7):\n",
        "    \"\"\"Multi-event prediction function\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize\n",
        "    encoding = tokenizer(text, truncation=True, padding='max_length',\n",
        "                        max_length=config.max_length, return_tensors='pt')\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        probabilities = torch.softmax(outputs['event_type'], dim=1)\n",
        "\n",
        "    # Get all predictions sorted by probability\n",
        "    probs, indices = torch.sort(probabilities[0], descending=True)\n",
        "\n",
        "    # Convert to list of (event, certainty) tuples\n",
        "    event_classes = label_encoders.encoders['event_type'].classes_\n",
        "    all_predictions = [(event_classes[idx.item()], prob.item())\n",
        "                      for idx, prob in zip(indices, probs)]\n",
        "\n",
        "    # Determine primary event and certainty\n",
        "    primary_event = all_predictions[0][0]\n",
        "    primary_certainty = all_predictions[0][1]\n",
        "\n",
        "    # If certainty is high enough, return single event\n",
        "    if primary_certainty >= certainty_threshold:\n",
        "        interpretation = \"Clear single event detected\"\n",
        "        events_info = [{\n",
        "            'event': primary_event,\n",
        "            'confidence': primary_certainty\n",
        "        }]\n",
        "        combined_certainty = primary_certainty\n",
        "    else:\n",
        "        # Accumulate events until threshold is met\n",
        "        selected_events = []\n",
        "        selected_certainties = []\n",
        "        cumulative_certainty = 0.0\n",
        "\n",
        "        for event, certainty in all_predictions:\n",
        "            if cumulative_certainty >= certainty_threshold or len(selected_events) >= 3:\n",
        "                break\n",
        "            selected_events.append(event)\n",
        "            selected_certainties.append(certainty)\n",
        "            cumulative_certainty += certainty * (1 - cumulative_certainty)\n",
        "\n",
        "        # Create interpretation\n",
        "        if len(selected_events) == 2:\n",
        "            interpretation = f\"Could be {selected_events[0]} or {selected_events[1]}\"\n",
        "        else:\n",
        "            interpretation = \"Multiple possible events detected\"\n",
        "\n",
        "        events_info = [{'event': e, 'confidence': c}\n",
        "                      for e, c in zip(selected_events, selected_certainties)]\n",
        "        combined_certainty = cumulative_certainty\n",
        "\n",
        "    # Get all other predictions\n",
        "    all_outputs = predict_event(text, model, tokenizer, label_encoders, device)\n",
        "\n",
        "    return {\n",
        "        'events': events_info,\n",
        "        'combined_certainty': combined_certainty,\n",
        "        'interpretation': interpretation,\n",
        "        'all_predictions': all_outputs['other_outputs']\n",
        "    }\n",
        "\n",
        "print(\"‚úì Prediction functions defined\")\n",
        "\n",
        "# %%\n",
        "# Cell 14: Load Best Model and Test\n",
        "# Load best model\n",
        "best_model_path = os.path.join(config.save_dir, 'best_model.pth')\n",
        "if os.path.exists(best_model_path):\n",
        "    checkpoint = torch.load(best_model_path, weights_only=False)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "    print(f\"‚úì Best model loaded\")\n",
        "    print(f\"  Best val loss: {checkpoint['best_val_loss']:.4f}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No best model found, using current model\")\n",
        "\n",
        "# %%\n",
        "# Cell 15: Test Examples\n",
        "print(\"\\nTesting predictions:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_examples = [\n",
        "    # Easy examples\n",
        "    \"I just got promoted to senior manager!\",\n",
        "    \"They laid me off after 10 years with the company\",\n",
        "    \"We're getting married next month!\",\n",
        "    \"I was diagnosed with diabetes yesterday\",\n",
        "\n",
        "    # Medium difficulty\n",
        "    \"Starting my freelance journey next month!\",\n",
        "    \"Got the promotion but no salary increase\",\n",
        "    \"We're taking a break to figure things out\",\n",
        "\n",
        "    # Hard examples\n",
        "    \"Oh great, another pay cut. Just what I needed.\",\n",
        "    \"They called it a 'mutual decision' but we all know what that means\",\n",
        "    \"Everyone says I'm lucky to still have a job\"\n",
        "]\n",
        "\n",
        "for i, text in enumerate(test_examples):\n",
        "    result = predict_event_multi(text, model, tokenizer, label_encoders, config.device)\n",
        "\n",
        "    print(f\"\\n{i+1}. Text: \\\"{text}\\\"\")\n",
        "    print(f\"   Interpretation: {result['interpretation']}\")\n",
        "\n",
        "    # Show events\n",
        "    for event_info in result['events']:\n",
        "        print(f\"   EVENT: {event_info['event']} ({event_info['confidence']:.2%})\")\n",
        "\n",
        "    # Show all predictions\n",
        "    preds = result['all_predictions']\n",
        "    print(f\"   GROUP: {preds['event_group']['prediction']} ({preds['event_group']['confidence']:.2%})\")\n",
        "    print(f\"   EMOTION: {preds['emotion']['prediction']} ({preds['emotion']['confidence']:.2%})\")\n",
        "    print(f\"   SENTIMENT: {preds['sentiment_valence']:.2f}\")\n",
        "    print(f\"   SARCASM: {preds['sarcasm']['prediction']}\")\n",
        "    print(f\"   TENSE: {preds['tense']['prediction']}\")\n",
        "    print(f\"   CERTAINTY: {preds['certainty']:.2f}\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "# %%\n",
        "# Cell 16: Save Final Model Package\n",
        "# Save everything in an organized way\n",
        "final_save_path = os.path.join(config.save_dir, 'final_model_package.pth')\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'label_encoders': label_encoders,\n",
        "    'config': config,\n",
        "    'tokenizer_name': config.model_name,\n",
        "    'event_classes': list(label_encoders.encoders['event_type'].classes_),\n",
        "    'emotion_classes': list(label_encoders.encoders['emotion'].classes_),\n",
        "    'tense_classes': list(label_encoders.encoders['tense'].classes_),\n",
        "    'event_group_classes': list(label_encoders.encoders['event_group'].classes_),\n",
        "}, final_save_path)\n",
        "\n",
        "# Save tokenizer\n",
        "tokenizer_path = os.path.join(config.save_dir, 'tokenizer')\n",
        "tokenizer.save_pretrained(tokenizer_path)\n",
        "\n",
        "# Save label encoders separately for compatibility\n",
        "import pickle\n",
        "for name, encoder in label_encoders.encoders.items():\n",
        "    with open(os.path.join(config.save_dir, f'le_{name}.pkl'), 'wb') as f:\n",
        "        pickle.dump(encoder, f)\n",
        "\n",
        "# Save inference config as JSON\n",
        "inference_config = {\n",
        "    'model_name': config.model_name,\n",
        "    'max_length': config.max_length,\n",
        "    'multi_event_threshold': config.multi_event_threshold,\n",
        "    'device': str(config.device),\n",
        "    'num_classes': label_encoders.num_classes,\n",
        "    'save_dir': config.save_dir\n",
        "}\n",
        "\n",
        "with open(os.path.join(config.save_dir, 'inference_config.json'), 'w') as f:\n",
        "    json.dump(inference_config, f, indent=2)\n",
        "\n",
        "print(f\"\\n‚úì Everything saved to: {config.save_dir}\")\n",
        "print(f\"  - Final model package: final_model_package.pth\")\n",
        "print(f\"  - Tokenizer: tokenizer/\")\n",
        "print(f\"  - Label encoders: le_*.pkl\")\n",
        "print(f\"  - Best model: best_model.pth\")\n",
        "print(f\"  - Inference config: inference_config.json\")\n",
        "\n",
        "# %%\n",
        "# Cell 17: Quick Helper Functions\n",
        "def quick_predict(text):\n",
        "    \"\"\"Quick prediction using the loaded model\"\"\"\n",
        "    return predict_event_multi(text, model, tokenizer, label_encoders, config.device)\n",
        "\n",
        "def show_confidence_distribution(text):\n",
        "    \"\"\"Show confidence distribution for all event types\"\"\"\n",
        "    model.eval()\n",
        "    encoding = tokenizer(text, truncation=True, padding='max_length',\n",
        "                        max_length=config.max_length, return_tensors='pt')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(encoding['input_ids'].to(config.device),\n",
        "                       encoding['attention_mask'].to(config.device))\n",
        "        probs = torch.softmax(outputs['event_type'], dim=1)[0]\n",
        "\n",
        "    # Get top 10\n",
        "    top_probs, top_indices = torch.topk(probs, 10)\n",
        "\n",
        "    print(f\"\\nTop 10 event predictions for: \\\"{text}\\\"\")\n",
        "    for i, (idx, prob) in enumerate(zip(top_indices, top_probs)):\n",
        "        event = label_encoders.encoders['event_type'].classes_[idx]\n",
        "        print(f\"{i+1:2d}. {event:30s} {prob.item():.2%}\")\n",
        "\n",
        "# Test the helper\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Testing helper functions:\")\n",
        "show_confidence_distribution(\"I got laid off but already have 3 interviews lined up\")\n",
        "\n",
        "# %%\n",
        "# Cell 18: Interactive User Testing\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"INTERACTIVE TESTING MODE\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nEnter text to analyze (or 'quit' to exit)\")\n",
        "print(\"Commands:\")\n",
        "print(\"  - 'quit' or 'q': exit\")\n",
        "print(\"  - 'top10': show top 10 predictions for last text\")\n",
        "print(\"  - 'examples': show example texts\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "example_texts = [\n",
        "    \"I finally got the promotion I've been working towards!\",\n",
        "    \"My contract wasn't renewed, time to look for something new\",\n",
        "    \"Starting my own business after 15 years in corporate\",\n",
        "    \"The doctor says I need surgery next month\",\n",
        "    \"We're expecting our first baby!\",\n",
        "    \"Another reorganization, and I'm being moved to a different department\"\n",
        "]\n",
        "\n",
        "last_text = \"\"\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"\\nEnter text: \").strip()\n",
        "\n",
        "    if user_input.lower() in ['quit', 'exit', 'q']:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    elif user_input.lower() == 'examples':\n",
        "        print(\"\\nExample texts:\")\n",
        "        for i, ex in enumerate(example_texts, 1):\n",
        "            print(f\"{i}. {ex}\")\n",
        "        continue\n",
        "\n",
        "    elif user_input.lower() == 'top10' and last_text:\n",
        "        show_confidence_distribution(last_text)\n",
        "        continue\n",
        "\n",
        "    elif user_input == '':\n",
        "        continue\n",
        "\n",
        "    # Make prediction\n",
        "    last_text = user_input\n",
        "    result = predict_event_multi(user_input, model, tokenizer, label_encoders, config.device)\n",
        "\n",
        "    # Display results\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ANALYSIS RESULTS\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    print(f\"\\nüìù Text: \\\"{user_input}\\\"\")\n",
        "    print(f\"\\nüéØ {result['interpretation']}\")\n",
        "\n",
        "    # Event predictions\n",
        "    print(\"\\nüìä Event Predictions:\")\n",
        "    for i, event_info in enumerate(result['events'], 1):\n",
        "        emoji = \"‚úÖ\" if i == 1 else \"üî∏\"\n",
        "        print(f\"   {emoji} {event_info['event']:25s} ({event_info['confidence']:.1%})\")\n",
        "\n",
        "    # Other predictions\n",
        "    preds = result['all_predictions']\n",
        "\n",
        "    print(f\"\\nüìÅ Event Group: {preds['event_group']['prediction']} ({preds['event_group']['confidence']:.1%})\")\n",
        "\n",
        "    # Emotion with emoji\n",
        "    emotion = preds['emotion']['prediction']\n",
        "    emotion_emojis = {\n",
        "        'joy': 'üòä', 'sadness': 'üò¢', 'anger': 'üò†', 'fear': 'üò®',\n",
        "        'surprise': 'üò≤', 'disgust': 'ü§¢', 'neutral': 'üòê', 'anxiety': 'üò∞',\n",
        "        'hope': 'ü§ó', 'pride': 'üòå', 'disappointment': 'üòû', 'relief': 'üòå'\n",
        "    }\n",
        "    emoji = emotion_emojis.get(emotion, 'üîµ')\n",
        "    print(f\"üí≠ Emotion: {emotion} {emoji} ({preds['emotion']['confidence']:.1%})\")\n",
        "\n",
        "    # Sentiment with bar\n",
        "    sentiment = preds['sentiment_valence']\n",
        "    bar_length = 20\n",
        "    filled = int(sentiment * bar_length)\n",
        "    bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)\n",
        "    print(f\"üìà Sentiment: [{bar}] {sentiment:.2f}\")\n",
        "\n",
        "    # Sarcasm\n",
        "    if preds['sarcasm']['prediction'] == 'TRUE':\n",
        "        print(f\"üôÑ Sarcasm: DETECTED! ({preds['sarcasm']['confidence']:.1%})\")\n",
        "    else:\n",
        "        print(f\"üìå Sarcasm: Not detected\")\n",
        "\n",
        "    # Tense and Certainty\n",
        "    print(f\"‚è∞ Tense: {preds['tense']['prediction']}\")\n",
        "    print(f\"üé≤ Certainty: {preds['certainty']:.2f}\")\n",
        "\n",
        "    print(f\"\\nüí° Tip: Type 'top10' to see confidence distribution for all events\")\n",
        "\n",
        "print(\"\\n‚úÖ Session ended. Model and results saved to:\", config.save_dir)"
      ],
      "metadata": {
        "id": "Sv1oAcBMKdUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E2_JIIkAJgwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your already trained model and save clean weights\n",
        "import torch\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "# Mount drive if not already mounted\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define minimal classes that the checkpoint expects (just empty shells)\n",
        "class MultiTaskLabelEncoders:\n",
        "    def __init__(self):\n",
        "        self.encoders = {}\n",
        "        self.num_classes = {}\n",
        "\n",
        "class Config:\n",
        "    pass\n",
        "\n",
        "save_dir = '/content/drive/MyDrive/EC-model-v2'\n",
        "\n",
        "print(\"Loading your existing trained model...\")\n",
        "# Load with weights_only=False since it's your own trusted model\n",
        "checkpoint = torch.load(os.path.join(save_dir, 'best_model.pth'),\n",
        "                       map_location='cpu',\n",
        "                       weights_only=False)\n",
        "\n",
        "# Extract just the model weights\n",
        "print(\"Extracting clean weights...\")\n",
        "model_weights = checkpoint['model_state_dict']\n",
        "\n",
        "# Save ONLY the weights (no classes or other objects)\n",
        "clean_path = os.path.join(save_dir, 'model_weights_clean.pth')\n",
        "torch.save(model_weights, clean_path)\n",
        "print(f\"‚úì Saved clean weights to: {clean_path}\")\n",
        "\n",
        "# Verify file size\n",
        "size_mb = os.path.getsize(clean_path) / (1024 * 1024)\n",
        "print(f\"‚úì File size: {size_mb:.1f} MB\")\n",
        "\n",
        "# Quick check - show some layer names\n",
        "print(f\"‚úì Total weight tensors: {len(model_weights)}\")\n",
        "print(\"\\nSample layers:\")\n",
        "for i, key in enumerate(list(model_weights.keys())[:5]):\n",
        "    print(f\"  - {key}\")\n",
        "print(\"  ...\")\n",
        "print(\"‚úì Ready to download and use locally!\")"
      ],
      "metadata": {
        "id": "B6AWqoRmJFeO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}